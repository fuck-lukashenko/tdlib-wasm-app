#!/usr/bin/env node
const dotenv = require('dotenv');
dotenv.config({ path: `.env.${process.env.NODE_ENV}.local` });
dotenv.config({ path: `.env.${process.env.NODE_ENV}` });
dotenv.config({ path: '.env.local' });
dotenv.config();

const { createReadStream, promises: { readdir, stat: getStats } } = require('fs');
const { resolve, join } = require('path');
const S3 = require('aws-sdk/clients/s3');
const { getMIMEType } = require('node-mime-types');
const open = require('open');

const s3 = new S3({
  signatureVersion: 'v4',
  accessKeyId: process.env.S3_KEY,
  secretAccessKey: process.env.S3_SECRET,
});

// upload file
const uploadFile = async function uploadFile({ path, params, options } = {}) {
  const parameters = { ...params };
  const opts = { ...options };

  try {
    const rstream = createReadStream(resolve(path));

    rstream.once('error', (err) => {
      console.error(`Unable to upload file ${path}, ${err.message}`);
    });

    parameters.Body = rstream;
    parameters.ContentType = getMIMEType(path);
    await s3.upload(parameters, opts).promise();

    console.info(`File ${parameters.Key} (${parameters.ContentType}) uploaded to bucket ${parameters.Bucket}`);
  } catch (e) {
    throw new Error(`Unable to upload file ${path} at ${parameters.Key}, ${e.message}`);
  }

  return true;
};

// upload directory and its sub-directories if any
const uploadDirectory = async function uploadDirectory({
  path,
  params,
  options,
  rootKey,
} = {}) {
  const parameters = { ...params };
  const opts = { ...options };
  const root = rootKey && rootKey.constructor === String ? rootKey : '';
  let dirPath;

  try {
    dirPath = resolve(path);
    const dirStats = await getStats(dirPath);

    if (!dirStats.isDirectory()) {
      throw new Error(`${dirPath} is not a directory`);
    }

    console.info(`Uploading directory ${dirPath}...`);

    const filenames = await readdir(dirPath);

    if (Array.isArray(filenames)) {
      await Promise.all(filenames.map(async (filename) => {
        const filepath = `${dirPath}/${filename}`;
        const fileStats = await getStats(filepath);

        if (fileStats.isFile()) {
          parameters.Key = join(root, filename);
          await uploadFile({
            path: filepath,
            params: parameters,
            options: opts,
          });
        } else if (fileStats.isDirectory()) {
          await uploadDirectory({
            params,
            options,
            path: filepath,
            rootKey: join(root, filename),
          });
        }
      }));
    }
  } catch (e) {
    throw new Error(`Unable to upload directory ${path}, ${e.message}`);
  }

  console.info(`Directory ${dirPath} successfully uploaded`);
  return true;
};

(async () => {
  try {
    console.info('Uploading files to AWS S3...\n');

    const { LocationConstraint: bucketRegion } = (
      await s3.getBucketLocation({ Bucket: process.env.S3_BUCKET }).promise()
    );

    await uploadDirectory({
      path: resolve(__dirname, '../build'),
      params: {
        Bucket: process.env.S3_BUCKET,
      },
      options: {},
      rootKey: '',
    });

    console.info('\nApplication successfully deployed to AWS S3.');

    const url = [
      [
        'https://s3',
        process.env.S3_USE_REGION && bucketRegion,
        'amazonaws.com',
      ].filter(Boolean).join('.'),
      process.env.S3_BUCKET,
      'index.html',
    ].join('/');
    console.info(`Url: ${url}`);
    open(url);
  } catch (e) {
    console.error(e);
  }
})();
